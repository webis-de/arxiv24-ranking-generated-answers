{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/topics/topics.txt'\n",
    "\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "def load_topics(path):\n",
    "    with open(path) as f:\n",
    "        root = ET.fromstring(f.read())\n",
    "    topic_dict = {}\n",
    "    for topic in root.findall(\"topic\"):\n",
    "        topic_id = topic.findtext(\"id\")\n",
    "        topic_query = topic.findtext(\"query\")\n",
    "        if topic_id and topic_query:\n",
    "            topic_dict[topic_id] = topic_query.strip() # .lower()\n",
    "    topics = pd.DataFrame(topic_dict.items(), columns=[\"qid\", \"query\"]) \n",
    "    # topics[\"query\"] = topics[\"query\"].str.replace(r'\\W+', ' ', regex=True)\n",
    "    return topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "openai.organization = os.environ[\"OPENAI_ORG\"]\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "parameters = {\n",
    "    \"temperature\": 0.75,\n",
    "    \"max_tokens\": 512,\n",
    "    \"number_of_answers\": 10\n",
    "}\n",
    "\n",
    "prompts=[\"<query>\", \"Q: <query>\\nA:\", \"Question: <query>\\nAnswer:\", \"You are a helpful medical knowledge assistant. Provide useful, complete, and scientifically-grounded answers to common consumer search queries about health.\\nQuestion: <query>\\nComplete Answer:\"]\n",
    "promp_identifiers=[\"no_prompt\", \"q\", \"question\", \"multimedqa\"]\n",
    "\n",
    "\n",
    "\n",
    "def generate_chatgpt_answers(topics, max_retries=3, max_rows=100, pre_prompt=\"<query>\", out_file=\"answers/chatgpt.csv\"):\n",
    "    generated_answers = 0\n",
    "    for index, row in topics.iterrows():\n",
    "        if row['answer_0'] != \"\":\n",
    "            continue\n",
    "        if generated_answers >= max_rows:\n",
    "            break\n",
    "        generated_answers += 1\n",
    "        prompt = row['query']\n",
    "        if \"<query>\" in pre_prompt:\n",
    "            prompt = pre_prompt.replace(\"<query>\", prompt)\n",
    "        else:\n",
    "            prompt = pre_prompt + \" \" + prompt\n",
    "        for i in range(max_retries):\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=parameters[\"temperature\"],\n",
    "                    max_tokens=parameters[\"max_tokens\"],\n",
    "                    n=parameters[\"number_of_answers\"],\n",
    "                )\n",
    "                for i, choice in enumerate(response.choices):\n",
    "                    # add column for each answer\n",
    "                    topics.at[index, f'answer_{i}'] = choice.message.content\n",
    "                # save intermediate answers after each row\n",
    "                topics.iloc[:index+1].to_csv(out_file, index=False)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error on topic: {prompt}. Retrying ({i+1}/3)...\")\n",
    "                print(f\"Error message: {e}\")\n",
    "                time.sleep(30)\n",
    "                if i == 2:\n",
    "                    topics.at[index, 'answer'] = \"\"\n",
    "    return topics\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    out_file = f'answers/chatgpt_{promp_identifiers[i]}.csv'\n",
    "    topics = load_topics(file_path)\n",
    "    topics['answer_0'] = \"\"\n",
    "    topics.to_csv(out_file, index=False)\n",
    "    all_answers_chatgpt = pd.read_csv(out_file)\n",
    "    # replace Nan with empty string\n",
    "    all_answers_chatgpt = all_answers_chatgpt.fillna(\"\")\n",
    "    questions_with_answers = generate_chatgpt_answers(all_answers_chatgpt, max_rows=100, pre_prompt=prompt, out_file=out_file)\n",
    "    questions_with_answers.to_csv(out_file, index=False)\n",
    "    # merge topics with all_answers_chatgpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
